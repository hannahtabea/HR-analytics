ggplot(ibm_126, aes(x = Attrition, y = JobSatisfaction,fill = Attrition))+
geom_boxplot(width=0.1)+
scale_fill_manual(values = myCol)+
ylab("Job Satisfaction")+
xlab("Employee Attrition")+
theme_custom()
ggplot(ibm_126, aes(x = Attrition, y = JobSatisfaction,fill = Attrition))+
geom_boxplot(width=0.1)+
scale_fill_manual(values = myCol)+
ylab("Job Satisfaction")+
xlab("Employee Attrition")+
theme_custom()+
ggtitle("Are leavers less satisfied than stayers?")
library(vcd)
library(vcdExtra)
f <- mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE)
f
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE))
fig2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126,
main = "Job Involvement against Turnover", shade = TRUE, legend = TRUE))
fig3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126,
main = "Work-Life-Balance against Turnover", shade = TRUE, legend = TRUE))
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE))
grid.arrange(fig1,fig2,fig3,fig4)
library(gridGraphics)
fig1<-grid.grab(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE))
fig2<-grid.grab(mosaic(~ Attrition + JobInvolvement, data = ibm_126,
main = "Job Involvement against Turnover", shade = TRUE, legend = TRUE))
fig3<-grid.grab(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126,
main = "Work-Life-Balance against Turnover", shade = TRUE, legend = TRUE))
fig4<-grid.grab(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE))
grid.arrange(fig1,fig2,fig3,fig4)
mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE)
fig1<-grid.grab()
mosaic(~ Attrition + JobInvolvement, data = ibm_126,
main = "Job Involvement against Turnover", shade = TRUE, legend = TRUE)
fig2<-grid.grab()
mosaic(~ Attrition + WorkLifeBalance, data = ibm_126,
main = "Work-Life-Balance against Turnover", shade = TRUE, legend = TRUE)
fig3<-grid.grab()
mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE)
fig4<-grid.grab()
grid.newpage()
grid.arrange(fig1,fig2,fig3,fig4)
fig1
mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE)
fig1<-grid.grab()
fig1<-grid.grabExpr()
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE))
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE))
fig1
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE))
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE), wrap = T)
fig4
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126,
main = "Environment Satisfaction against Turnover", shade = TRUE, legend = TRUE), wrap = T)
fig2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126,
main = "Job Involvement against Turnover", shade = TRUE, legend = TRUE), wrap = T)
fig3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126,
main = "Work-Life-Balance against Turnover", shade = TRUE, legend = TRUE), wrap = T)
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE), wrap = T)
grid.newpage()
grid.arrange(fig1,fig2,fig3,fig4)
?grid.arrange
??grid.arrange
library(gridExtra)
gridExtra::grid.arrange(fig1,fig2,fig3,fig4)
gridExtra::grid.arrange(fig1,fig2,fig3,fig4)
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126,
main = "Job Involvement against Turnover", shade = TRUE, legend = TRUE), wrap = T)
fig3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126,
main = "Work-Life-Balance against Turnover", shade = TRUE, legend = TRUE), wrap = T)
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126,
main = "Relationship Satisfaction against Turnover", shade = TRUE, legend = TRUE), wrap = T)
grid.newpage()
gridExtra::grid.arrange(fig1,fig2,fig3,fig4)
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
grid.newpage()
gridExtra::grid.arrange(fig1,fig2,fig3,fig4)
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
grid.newpage()
gridExtra::grid.arrange(fig1,fig2,fig3,fig4)
fig1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
fig4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
grid.newpage()
gridExtra::grid.arrange(fig1,fig2,fig3,fig4)
grid.newpage()
g <- gridExtra::grid.arrange(mo1,mo2,mo3,mo4)
ggsave(file="whatever.pdf", g, path = path_plot)
mo1<-grid.grabExpr(mosaic(~ Attrition + EnvironmentSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
mo2<-grid.grabExpr(mosaic(~ Attrition + JobInvolvement, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
mo3<-grid.grabExpr(mosaic(~ Attrition + WorkLifeBalance, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
mo4<-grid.grabExpr(mosaic(~ Attrition + RelationshipSatisfaction, data = ibm_126, shade = TRUE, legend = TRUE), wrap = T)
grid.newpage()
g <- gridExtra::grid.arrange(mo1,mo2,mo3,mo4)
ggsave(file="whatever.pdf", g, path = path_plot)
ggsave(file=paste0(current_date,"_whatever.png"), g, path = path_plot,width = 20, height = 10, units = "cm")
# create data folds for cross validation
myFolds <- createFolds(ibm_final$Attrition, k = 5)
f1 <- function (data, lev = NULL, model = NULL) {
precision <- posPredValue(data$pred, data$obs, positive = "Yes")
recall  <- sensitivity(data$pred, data$obs, postive = "Yes")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
f1_val
}
# Create reusable trainControl object: myControl
myControl <- trainControl(
method = "repeatedcv",
repeats = 5,
summaryFunction = f1,
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE,
savePredictions = "final",
index = myFolds
)
#---------------------------------------------------------
# FIND HIGHLY CORRELATED VARS
#----------------------------------------------------------
# load the library
#library(mlbench)
library(caret)
# create data folds for cross validation
myFolds <- createFolds(ibm_final$Attrition, k = 5)
f1 <- function (data, lev = NULL, model = NULL) {
precision <- posPredValue(data$pred, data$obs, positive = "Yes")
recall  <- sensitivity(data$pred, data$obs, postive = "Yes")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
f1_val
}
# Create reusable trainControl object: myControl
myControl <- trainControl(
method = "repeatedcv",
repeats = 5,
summaryFunction = f1,
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE,
savePredictions = "final",
index = myFolds
)
# create data folds for cross validation
myFolds <- createFolds(ibm_final$Attrition, k = 5)
f1 <- function (data, lev = NULL, model = NULL) {
precision <- posPredValue(data$pred, data$obs, positive = "Yes")
recall  <- sensitivity(data$pred, data$obs, postive = "Yes")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
f1_val
}
library(caret)
# find numeric values
nums <- unlist(lapply(ibm_reduced, is.numeric))
# save numeric variables for later
ibm_nums <- ibm_reduced[,nums]
# show numeric variables
head(ibm_nums)
# calculate correlation matrix
correlationMatrix <- cor(ibm_nums)
# summarize the correlation matrix
correlationMatrix
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
# print colnames of highly correlated attributes
colnames(ibm_nums[,highlyCorrelated])
correlationMatrix[,highlyCorrelated]
# remove highly correlated variables to overcome multicollinearity
colnames(ibm_nums)
highlyCorrelated <- c(1,7,11,16,17,19)
ibm_nums <- ibm_nums[,-highlyCorrelated]
#----------------------------------------------------------
# CREATE DUMMY VARIABLES
#----------------------------------------------------------
# select factor variables to convert, but leave Attrition out
vars_to_dummy <- ibm_reduced[,sapply(ibm_reduced, is.factor) & colnames(ibm_reduced) != "Attrition"]
head(vars_to_dummy)
# Create dummy variables with caret
dummies <- dummyVars( ~ ., data = vars_to_dummy)
ibm_dummy <- predict(dummies, newdata = vars_to_dummy)
# New dataframe to work with later
ibm_sample <- data.frame(ibm_dummy, ibm_nums, Attrition = ibm_reduced$Attrition)
View(ibm_sample)
#--------------------------------------------------------------------------------
# REMOVE NON INFORMATIVE PREDICTORS
#--------------------------------------------------------------------------------
# remove near zero variables (except for attr)
remove_cols <- nearZeroVar(ibm_sample, names = TRUE)
remove_cols
# Get all column names
all_cols <- names(ibm_sample)
# Remove from data
ibm_final<- ibm_sample[ , setdiff(all_cols, remove_cols)]
# make sure that factor levels of attrition are correctly ordered
levels(ibm_final$Attrition)
ibm_final$Attrition <- factor(ibm_final$Attrition, levels = c("Yes", "No"))
# double check
levels(ibm_final$Attrition)
# clean up data
ibm_126 <- ibm_126[,-c("DailyRate","EducationField", "EmployeeCount", "EmployeeNumber",
"MonthlyRate","StandardHours","TotalWorkingYears","StockOptionLevel","Gender",
"Over18", "OverTime", "median_compensation")]
ibm_reduced <- as.data.frame(unclass(ibm_126),stringsAsFactors=TRUE)
#---------------------------------------------------------
# FIND HIGHLY CORRELATED VARS
#----------------------------------------------------------
library(caret)
# find numeric values
nums <- unlist(lapply(ibm_reduced, is.numeric))
# save numeric variables for later
ibm_nums <- ibm_reduced[,nums]
# show numeric variables
head(ibm_nums)
# calculate correlation matrix
correlationMatrix <- cor(ibm_nums)
# summarize the correlation matrix
correlationMatrix
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
# print colnames of highly correlated attributes
colnames(ibm_nums[,highlyCorrelated])
correlationMatrix[,highlyCorrelated]
# remove highly correlated variables to overcome multicollinearity
colnames(ibm_nums)
highlyCorrelated <- c(1,7,11,16,17,19)
ibm_nums <- ibm_nums[,-highlyCorrelated]
# select factor variables to convert, but leave Attrition out
vars_to_dummy <- ibm_reduced[,sapply(ibm_reduced, is.factor) & colnames(ibm_reduced) != "Attrition"]
head(vars_to_dummy)
# Create dummy variables with caret
dummies <- dummyVars( ~ ., data = vars_to_dummy)
ibm_dummy <- predict(dummies, newdata = vars_to_dummy)
# New dataframe to work with later
ibm_sample <- data.frame(ibm_dummy, ibm_nums, Attrition = ibm_reduced$Attrition)
View(ibm_sample)
#--------------------------------------------------------------------------------
# REMOVE NON INFORMATIVE PREDICTORS
#--------------------------------------------------------------------------------
# remove near zero variables (except for attr)
remove_cols <- nearZeroVar(ibm_sample, names = TRUE)
remove_cols
# Get all column names
all_cols <- names(ibm_sample)
# Remove from data
ibm_final<- ibm_sample[ , setdiff(all_cols, remove_cols)]
# make sure that factor levels of attrition are correctly ordered
levels(ibm_final$Attrition)
ibm_final$Attrition <- factor(ibm_final$Attrition, levels = c("Yes", "No"))
# double check
levels(ibm_final$Attrition)
#-------------------------------------------------------------------------
# MODELLING PART
#-------------------------------------------------------------------------
library(naivebayes)
library(ranger)
# create data folds for cross validation
myFolds <- createFolds(ibm_final$Attrition, k = 5)
f1 <- function (data, lev = NULL, model = NULL) {
precision <- posPredValue(data$pred, data$obs, positive = "Yes")
recall  <- sensitivity(data$pred, data$obs, postive = "Yes")
f1_val <- (2 * precision * recall) / (precision + recall)
names(f1_val) <- c("F1")
f1_val
}
# Create reusable trainControl object: myControl
myControl <- trainControl(
method = "repeatedcv",
repeats = 5,
summaryFunction = f1,
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE,
savePredictions = "final",
index = myFolds
)
# Create baseline model
model_baseline <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = "glm",
# family = "binomial",
trControl = myControl
)
model_baseline
summary(model_baseline)
# Create baseline model
model_baseline <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = "glm",
family = "binomial",
trControl = myControl
)
summary(model_baseline)
# Create reusable train function
methods <- c("glm","glmnet","naive_bayes", "ranger", "xgbtree")
train_model <- function(method) {
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = method,
trControl = myControl
)
assign(paste0("model_", method))
}
lapply(methods, train_model, data = ibm_final)
lapply(methods, train_model)
method
train_model <- function(i) {
method <- methods[[i]]
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = method,
trControl = myControl
)
assign(paste0("model_", method))
}
lapply(methods, train_model)
i
i=1
methods[[i]]
?assign
train_model <- function(i) {
method <- methods[[i]]
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = method,
trControl = myControl
)
assign(paste0("model_", method),model)
}
lapply(methods, train_model)
x <- 1:5
x
methods
is.list(methods)
is.list(x)
is.vector(methods)
is.vector(x)
method = "glm"
assign(paste0("model_", method),baseline_model)
assign(paste0("model_", method),model_baseline)
?lapply
# Create reusable train function
methods <- c("glm","glmnet","naive_bayes", "ranger", "xgbtree")
train_model <- function(x) {
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = x,
trControl = myControl
)
assign(paste0("model_", x),model)
}
lapply(methods, train_model)
library(xgboost)
train_model <- function(x) {
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = x,
trControl = myControl
)
return(assign(paste0("model_", x),model))
}
lapply(methods, train_model)
x
Y <- lapply(methods, train_model)
Y
methods <- c("glm","glmnet","naive_bayes", "ranger", "xgbtree")
train_model <- function(x) {
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = x,
trControl = myControl
)
return(assign(paste0("model_", x),model), envir = .GlobalEnv)
}
lapply(methods, train_model)
train_model <- function(x) {
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = x,
trControl = myControl
)
return(assign(paste0("model_", x),model, envir = .GlobalEnv))
}
lapply(methods, train_model)
model_glm
summary(model_glm)
base_Pred <- predict.train(model_glm, ibm_final, type = "raw")
confusionMatrix(base_Pred, ibm_final$Attrition, mode = "prec_recall")
library(xgboost)
# Create reusable train function
methods <- c("glm","glmnet","naive_bayes", "ranger", "xgbTree")
train_model <- function(x) {
model <- caret::train(
Attrition ~ MonthlyIncome + JobSatisfaction + MonthlyIncome*JobSatisfaction,
data = ibm_final,
metric = "F1",
method = x,
trControl = myControl
)
return(assign(paste0("model_", x),model, envir = .GlobalEnv))
}
lapply(methods, train_model)
# Create model_list
model_list <- list(baseline = model_glm, naive_bayes = model_naive_bayes,  glmnet = model_glmnet, random_forest = model_ranger, xgboost= model_xgTree)
# Create model_list
model_list <- list(baseline = model_glm, naive_bayes = model_naive_bayes,  glmnet = model_glmnet, random_forest = model_ranger, xgboost= model_xgbTree)
# Pass model_list to resamples(): resamples
resamples <- resamples(model_list)
# Summarize the results
summary(resamples)
bwplot(resamples, metric = "F1")
xgb_Pred <- predict.train(model_xgbTree, ibm_final, type = "raw")
confusionMatrix(xgb_Pred, ibm_final$Attrition, mode = "prec_recall")
# find numeric variables
ibm_nums <- ibm_reduced[ , .SD, .SDcols = is.numeric]
# find numeric variables
filter(ibm_reduced, is.numeric)
# find numeric variables
Filter(ibm_reduced, is.numeric)
ibm_reduced[, sapply(.SD, is.numeric)]
ibm_reduced
is.data.table(ibm_reduced)
is.data.table(ibm_126)
ibm_reduced <- ibm_126[,-c("DailyRate","EducationField", "EmployeeCount", "EmployeeNumber",
"MonthlyRate","StandardHours","TotalWorkingYears","StockOptionLevel","Gender",
"Over18", "OverTime", "median_compensation")]
View(ibm_126)
set.seed(123)
ibm_126 <- ibm_dat[sample(.N, 126)]
ibm_reduced <- ibm_126[,-c("DailyRate","EducationField", "EmployeeCount", "EmployeeNumber",
"MonthlyRate","StandardHours","TotalWorkingYears","StockOptionLevel","Gender",
"Over18", "OverTime", "median_compensation")]
ibm_reduced <- ibm_126[,-c("DailyRate","EducationField", "EmployeeCount", "EmployeeNumber",
"MonthlyRate","StandardHours","TotalWorkingYears","StockOptionLevel","Gender",
"Over18", "OverTime", "median_compensation")]
lapply(ibm_reduced[sapply(ibm_reduced, is.character)],
as.factor)
# convert all characters to factors
ibm_reduced[,(names(ibm_reduced[, sapply(.SD,is.character)])) := lapply(.SD, as.factor), .SDcols = names(ibm_reduced[, sapply(.SD,is.character)])]
str(ibm_reduced)
# save all character variables
ibm_chars <- names(ibm_reduced[, sapply(.SD,is.character)])
str(ibm_chars)
ibm_chars
# select char variables to convert, but leave Attrition out
vars_to_dummy <- ibm_reduced[,ibm_chars & - "Attrition"]
# select char variables to convert, but leave Attrition out
vars_to_dummy <- ibm_reduced[,ibm_chars][, - Attrition]
# select char variables to convert, but leave Attrition out
vars_to_dummy <- ibm_reduced[,ibm_chars][, - "Attrition"]
ibm_chars
ibm_reduced[,ibm_chars]
ibm_reduced[,get(ibm_chars)]
ibm_reduced[,(ibm_chars)]
ibm_reduced[,..ibm_chars]
vars_to_dummy <- ibm_reduced[, .SD, .SDcols = ibm_chars][, - "Attrition"]
vars_to_dummy
ibm_chars
ibm_reduced[, sapply(.SD,is.character)]
ibm_nums
ibm_dat <- fread(path_dat, stringsAsFactors = T)
ibm_dat[ , `:=`(median_compensation = median(MonthlyIncome)),by = .(JobLevel) ]
ibm_dat[ , `:=`(CompensationRatio = (MonthlyIncome/median_compensation)), by =. (JobLevel)]
ibm_dat[ , `:=`(CompensationLevel = factor(fcase(
CompensationRatio %between% list(0.75,1.25), "Average",
CompensationRatio %between% list(0, 0.74), "Below",
CompensationRatio %between% list(1.26,2),  "Above"),
levels = c("Below","Average","Above"))),
by = .(JobLevel) ]
set.seed(123)
ibm_126 <- ibm_dat[sample(.N, 126)]
# save all character variables
ibm_chars <- names(ibm_reduced[, sapply(.SD,is.factor)])
ibm_chars
str(ibm_reduced)
